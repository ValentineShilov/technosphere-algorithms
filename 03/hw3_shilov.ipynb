{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valentine Shilov\n",
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 30 апреля 2018, 06:00   \n",
    "**Штраф за опоздание:** -2 балла после 06:00 30 апреля, -4 балла после 06:00 7 мая, -6 баллов после 06:00 14 мая, -8 баллов после 06:00 21 мая\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return 1 - np.sum((l_c ** 2) / (l_s * (l_s + r_s)) +\\\n",
    "            (np.square(r_c)) / (r_s * (l_s + r_s)), axis=1)\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return -np.sum(l_c / l_s * np.log2(l_c / l_s), axis=1)-\\\n",
    "            np.sum(r_c/r_s*np.log2(r_c/r_s), axis=1)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return 1 - np.max(l_c / (l_s + r_s), axis=1) -\\\n",
    "            np.max(r_c / (l_s + r_s), axis=1)\n",
    "    \n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:np.int(np.sqrt(n_feature))])\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:np.int(np.log2(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        #sort\n",
    "        x_sorted, y_sorted=self.__sort_samples(x,y)\n",
    "        num_class=self.num_class\n",
    "        c = self.min_samples_split // 2\n",
    "        c = np.int(self.min_samples_split / 2 - 1)\n",
    "        \n",
    "        #cut middle \n",
    "        if(c != 0 ):\n",
    "            y_middle = y_sorted[c:-c] \n",
    "        else:\n",
    "            y_middle = y_sorted\n",
    "      \n",
    "        \n",
    "        r_delim_ind = np.where(y_middle[1:] != y_middle[:-1])[0] + c + 1\n",
    "        if len(r_delim_ind) == 0:\n",
    "            return np.inf, None\n",
    "        \n",
    "        eq_element_count = -np.append([c], r_delim_ind[:-1]) + r_delim_ind \n",
    "        delim_oht = np.zeros((r_delim_ind.shape[0], num_class))\n",
    "        delim_oht[np.arange(r_delim_ind.shape[0]), y_sorted[r_delim_ind - 1]] = 1\n",
    "\n",
    "        class_increments = eq_element_count.reshape(-1, 1) * delim_oht\n",
    "        class_increments[0] = class_increments[0] + np.bincount(y_sorted[:c], minlength=num_class)\n",
    "  \n",
    "        l_class_count = np.cumsum(class_increments, axis=0)\n",
    "        r_class_count = np.bincount(y_sorted, minlength=num_class) - l_class_count\n",
    "    \n",
    "        \n",
    "        l_count = r_delim_ind.reshape(l_class_count.shape[0], 1)\n",
    "        r_count = y_sorted.shape[0] - l_count\n",
    "        \n",
    "        \n",
    "        gs = self.G_function(l_class_count, l_count, r_class_count, r_count)\n",
    "        min_index = np.argmin(gs)\n",
    "        \n",
    "        delim_element_index = l_count[min_index][0]\n",
    "        \n",
    "        return gs[min_index], (x_sorted[delim_element_index] + x_sorted[delim_element_index - 1]) / 2\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        #create node if not the end\n",
    "        if  y.size < self.min_samples_split  or \\\n",
    "            (self.max_depth is not None and self.max_depth <= depth) or \\\n",
    "            self.sufficient_share <= np.bincount(y).argmax() / y.size:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(), np.bincount(y).astype(float) / y.size)\n",
    "        #find thresholds\n",
    "        fids = self.get_feature_ids(x.shape[1])\n",
    "        thresholds = np.array([self.__find_threshold(x[:, i], y) for i in fids])\n",
    "        \n",
    "        \n",
    "        best_threshold_id = thresholds[:, 0].argmin()\n",
    "        best_threshold = thresholds[best_threshold_id, 1]\n",
    "        \n",
    "        if best_threshold is None:\n",
    "            #create last leaf\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(), np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "       \n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, best_threshold_id, best_threshold)\n",
    "        #print(y.size, y_l.size)\n",
    "        if x_l.size == 0 or x_r.size == 0:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE,np.bincount(y).argmax(),np.bincount(y).astype(float) / y.size)\n",
    "        else:\n",
    "            self.tree[node_id] = (self.NON_LEAF_TYPE, best_threshold_id, best_threshold)\n",
    "            self.__fit_node(x_r, y_r, node_id * 2 + 2, depth + 1)\n",
    "            self.__fit_node(x_l, y_l,node_id * 2 + 1, depth + 1)\n",
    "        if self.G_function == self.__entropy:\n",
    "            g = self.__entrophy_calc(y)\n",
    "            g_l = self.__entrophy_calc(y_l)\n",
    "            g_r = self.__entrophy_calc(y_r)\n",
    "            self.feature_importances_[best_threshold_id] += self.__fimp_calc(y, y_l, y_r, g, g_l, g_r)   \n",
    "        elif self.G_function == self.__misclass:\n",
    "            g = self.__g_misclass_calc(y)\n",
    "            g_l = self.__g_misclass_calc(y_l)\n",
    "            g_r = self.__g_misclass_calc(y_r)\n",
    "            self.feature_importances_[best_threshold_id] += self.__fimp_calc(y, y_l, y_r, g, g_l, g_r)\n",
    "        elif self.G_function == self.__gini:\n",
    "            g = self.__gini_calc(y)\n",
    "            g_l = self.__gini_calc(y_l)\n",
    "            g_r = self.__gini_calc(y_r)\n",
    "            self.feature_importances_[best_threshold_id] += self.__fimp_calc(y, y_l, y_r, g, g_l, g_r)  \n",
    "\n",
    "    def __entrophy_calc(self, y):\n",
    "        return -(np.sum((np.unique(y, return_counts=True)[1] / y.size) * np.log2(np.unique(y, return_counts=True)[1] / y.size)))\n",
    "        \n",
    "    def __gini_calc(self, y_a):\n",
    "        return (1 - np.sum(np.unique(y_a, return_counts=True)[1]** 2 / (y_a.size *y_a.size)))\n",
    "                \n",
    "    def __g_misclass_calc(self, y_a):\n",
    "        return (1 - np.max(np.sum(np.unique(y_a, return_counts=True)[1] / y_a.size)))\n",
    "    \n",
    "    def __fimp_calc(self, y, y_l, y_r, g, g_l, g_r):\n",
    "        return (y.size*g - y_l.size*g_l - y_r.size*g_r)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        \n",
    "        if(self.feature_importances_ is None):\n",
    "            self.feature_importances_ = np.zeros(x.shape[1], dtype=float)\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= y.size\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 2.83 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 ms, sys: 0 ns, total: 56 ms\n",
      "Wall time: 54.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Speed Dating Data.csv', encoding='cp1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    \n",
    "    if not (type(df[col][0])==np.int64 or\\\n",
    "        type(df[col][0])==np.int64 or\\\n",
    "        type(df[col][0])==np.int or\\\n",
    "        type(df[col][0])==np.float or\\\n",
    "        df[col].isnull().sum()>500) or\\\n",
    "        str(col)==\"undergra\":\n",
    "        df.drop(col,axis=1, inplace=True)\n",
    "df=df.fillna(-100500)\n",
    "#fix 123,456.00 numbers\n",
    "def conv(i):\n",
    "    return np.float(i.replace(\",\", \"\"))\n",
    "a = df.drop('gender', axis=1).iloc[:,:].values.astype(str)\n",
    "a = np.vectorize(conv)(a)\n",
    "X = a.astype(np.float)\n",
    "y = df.loc[:, 'gender'].values.astype(np.int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 34.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 232 ms, sys: 0 ns, total: 232 ms\n",
      "Wall time: 232 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9776134853372336"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994033412887827"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "gender      0.456783\n",
      "idg         0.231786\n",
      "round       0.149109\n",
      "wave        0.100333\n",
      "tuition     0.052896\n",
      "condtn      0.006876\n",
      "position    0.001554\n",
      "mn_sat      0.000663\n",
      "dec         0.000000\n",
      "dec_o       0.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "MyDecisionTreeClassifier\n",
      "gender      0.203979\n",
      "idg         0.106151\n",
      "wave        0.083969\n",
      "round       0.044196\n",
      "condtn      0.015337\n",
      "tuition     0.012292\n",
      "mn_sat      0.001362\n",
      "dec         0.000000\n",
      "dec_o       0.000000\n",
      "samerace    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('DecisionTreeClassifier')\n",
    "print(pd.Series(index = df.columns[1:], data = clf.feature_importances_).\n",
    "      sort_values()[::-1].head(10))\n",
    "print('\\n\\nMyDecisionTreeClassifier')\n",
    "print(pd.Series(index = df.columns[1:], data = my_clf.feature_importances_).\n",
    "      sort_values()[::-1].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 110, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "parametrs = {\n",
    "    \"criterion\": [\"entropy\", \"gini\"],\n",
    "    \"min_samples_split\": np.arange(2, 10).tolist(),\n",
    "    \"max_depth\": np.arange(2, 16).tolist(),\n",
    "    \"n_estimators\": np.arange(50, 400,20).tolist()\n",
    "    }\n",
    "RS = RandomizedSearchCV(RandomForestClassifier(random_state=123), param_distributions=parametrs, n_iter=32, cv=3)\n",
    "RS.fit(X_train, y_train)\n",
    "print(RS.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
